version: 2.1
# Use a package of configuration called an orb.
orbs:
  # Choose either one of the orbs below
  # welcome: circleci/welcome-orb@0.4.1
  # aws-cli: circleci/aws-cli@2.0.3
# Define the jobs we want to run for this project
jobs:
  configure_infrastructure: 
    docker:
      - image: python:3.7-alpine3.11
    steps:
      - checkout
      - add_ssh_keys:
          fingerprints: ["9e:74:0a:09:37:a0:50:38:a8:70:a3:cb:d8:4d:40:14"] 
      - run:
          name: Install Ansible
          command: |
            apk add --update ansible
      - run:
          name: Run Playbook and Configure server
          command: |
            ansible-playbook -i inventory main.yml
  create_infrastructure: 
      docker:
        - image: amazon/aws-cli
      steps:
        - checkout
        - run:
            name: Create Cloudformation Stack
            command: |
              aws cloudformation deploy \
                --template-file template.yml \
                --stack-name myStack-${CIRCLE_WORKFLOW_ID:0:5} \
                --region us-east-1
  create_and_deploy_front_end:
    docker:
      - image: amazon/aws-cli
    steps:
        - checkout
        - run:
            name: Execute bucket.yml - Create Cloudformation Stack
            command: |
              aws cloudformation deploy \
              --template-file bucket.yml \
              --stack-name stack-create-bucket-${CIRCLE_WORKFLOW_ID:0:7} \
              --parameter-overrides MyBucketName="mybucket-${CIRCLE_WORKFLOW_ID:0:7}"
      # Uncomment the step below if yoou wish to upload all contents of the current directory to the S3 bucket
        - run: aws s3 sync . s3://mybucket-${CIRCLE_WORKFLOW_ID:0:7} --delete
  get_last_deployment_id:
    docker:
      - image: amazon/aws-cli
    steps:
        - checkout
        - run: yum install -y tar gzip
        - run:
            name: Fetch and save the old pipeline ID (bucket name) responsible for the last release.
            command: |
              aws cloudformation \
              list-exports --query "Exports[?Name==\`PipelineID\`].Value" \
              --no-paginate --output text > ~/textfile.txt
        - persist_to_workspace:
            root: ~/
            paths: 
              - textfile.txt

  promote_to_production:
    docker:
      - image: amazon/aws-cli
    steps:
        - checkout
        - run:
            name: Execute cloudfront.yml
            command: |
              aws cloudformation deploy \
              --template-file cloudfront.yml \
              --stack-name production-distro \
              --parameter-overrides PipelineID="mybucket-${CIRCLE_WORKFLOW_ID:0:7}"
  clean_up_old_front_end:
    docker:
        - image: amazon/aws-cli
    steps:
        - checkout
        - run: yum install -y tar gzip
        - attach_workspace:
            at: ~/
        - run:
            name: Destroy the previous S3 bucket and CloudFormation stack. 
            # Use $OldBucketID environment variable or mybucket644752792305 below.
            # Similarly, you can create and use $OldStackID environment variable in place of production-distro 
            command: |
              export OldBucketID=$(cat ~/textfile.txt)
              aws s3 rm "s3://${OldBucketID}" --recursive
workflows:
  myWorkflow:
    jobs:
      # - create_infrastructure
      # - configure_infrastructure
      - create_and_deploy_front_end
      - promote_to_production:
            requires: 
              - create_and_deploy_front_end
        - get_last_deployment_id
        - clean_up_old_front_end:
            requires:
              - get_last_deployment_id
              - promote_to_production